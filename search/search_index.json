{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#homepage","title":"Homepage","text":""},{"location":"#_1","title":"Home","text":""},{"location":"#mathematical-biosciences-lab","title":"Mathematical Biosciences Lab","text":"<p>Our lab is a multidisciplinary research team at the interface of mathematics and biology/life sciences. As part of the Department of Mathematical Sciences at Stellenbosch University in South Africa, we are a dynamic research group led by Prof Cang Hui, a SARChI Chair in Mathematical and Theoretical Physical Biosciences. Our interests lie in proposing models and theories for explaining emerging patterns in ecology. Ecology studies biodiversity in its variety and complexity. As ecological processes are highly complex and adaptive, we rely on the simplicity of mathematical language to build models and theoretical frameworks.</p>"},{"location":"#biomath-documents","title":"BioMath Documents","text":"<p>Welcome to the Mathematical Biosciences (BioMath) GitHub repository, a dedicated space for advancing the understanding and conservation of biodiversity through computational science. Here, we offer an array of R and Python workflows and coding tutorials designed specifically for modeling ecosystem complexity. Our resources are tailored to support researchers, conservationists, and students in their quest to unravel the intricate dynamics of ecosystems and to apply these insights towards effective biodiversity conservation strategies. Whether you are looking to enhance your analytical skills, develop sophisticated models, or explore innovative approaches to ecological research, our repository serves as a bridge between mathematical biosciences and practical conservation efforts. Dive into our content to discover tools and techniques that empower data-driven decision-making and foster a deeper connection with the natural world.</p>"},{"location":"#authors","title":"Authors","text":"<ul> <li>Sandra MacFadyen</li> </ul> <p>See also the list of contributors who participated in this project.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License MIT License - see the LICENSE.md file for details</p>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<ul> <li>National Institute for Theoretical and Computational Sciences (NITheCS)</li> </ul>"},{"location":"LICENSE/","title":"LICENSE","text":"<p>MIT License</p> <p>Copyright (c) 2024 Mathematical Biosciences, Stellenbosch University (SUN)</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"about/","title":"About","text":""},{"location":"about/#_1","title":"About","text":""},{"location":"about/#mathematical-biosciences-lab","title":"Mathematical Biosciences Lab","text":"<p>Our lab is a multidisciplinary research team at the interface of mathematics and biology/life sciences. As part of the Department of Mathematical Sciences at Stellenbosch University in South Africa, we are a dynamic research group led by Prof Cang Hui, a SARChI Chair in Mathematical and Theoretical Physical Biosciences. Our interests lie in proposing models and theories for explaining emerging patterns in ecology. Ecology studies biodiversity in its variety and complexity. As ecological processes are highly complex and adaptive, we rely on the simplicity of mathematical language to build models and theoretical frameworks.</p>"},{"location":"about/#biomath-documents","title":"BioMath Documents","text":"<p>Welcome to the Mathematical Biosciences (BioMath) GitHub repository, a dedicated space for advancing the understanding and conservation of biodiversity through computational science. Here, we offer an array of R and Python workflows and coding tutorials designed specifically for modeling ecosystem complexity. Our resources are tailored to support researchers, conservationists, and students in their quest to unravel the intricate dynamics of ecosystems and to apply these insights towards effective biodiversity conservation strategies. Whether you are looking to enhance your analytical skills, develop sophisticated models, or explore innovative approaches to ecological research, our repository serves as a bridge between mathematical biosciences and practical conservation efforts. Dive into our content to discover tools and techniques that empower data-driven decision-making and foster a deeper connection with the natural world.</p>"},{"location":"about/#authors","title":"Authors","text":"<ul> <li>Sandra MacFadyen</li> </ul> <p>See also the list of contributors who participated in this project.</p>"},{"location":"about/#license","title":"License","text":"<p>This project is licensed under the MIT License MIT License - see the LICENSE.md file for details</p>"},{"location":"about/#acknowledgments","title":"Acknowledgments","text":"<ul> <li>National Institute for Theoretical and Computational Sciences (NITheCS)</li> </ul>"},{"location":"dissimilarity-cube/","title":"Dissimilarity cube","text":""},{"location":"dissimilarity-cube/#specification-for-dissimilarity-cubes-and-their-production","title":"Specification for dissimilarity cubes and their production","text":"<p>This document presents the specification for \u201cdissimilarity cubes\u201d, to map compositional dissimilarity and turnover of species using occurrence data. It provides a workflow to compile co-occurrence matrices for species in a specified geographic area, source georeferenced environmental data, and map compositional dissimilarity using \u2018MS-GDM' and 'zetadiv'.</p>"},{"location":"dissimilarity-cube/#task-42-dissimilarity-cube-lead-sun","title":"Task 4.2: Dissimilarity cube [Lead: SUN]","text":"<p>Design workflows to compile a co-occurrence matrix for species in a geographic area, source georeferenced environmental data, and map compositional dissimilarity using \u2018MS-GDM', 'zetadiv', and 'SSDM' R packages. This includes identifying bioregions and predicting future compositional turnover and bioregion shifts.</p> <ul> <li>Nov 2024: M13 \u2013 Code design: Map compositional dissimilarity &amp; turnover</li> <li>Apr 2025: M14 \u2013 Code test: Map compositional dissimilarity &amp; turnover</li> </ul>"},{"location":"dissimilarity-cube/#introduction","title":"Introduction","text":"<p>Biodiversity monitoring is fundamental in understanding and conserving ecological dynamics, particularly in the context of accelerating global change. Central to these efforts is the concept of dissimilarity, which quantifies the differences in species composition across spatial or temporal scales and provides critical insights into ecosystem diversity and structure. Dissimilarity, alongside traditional biodiversity metrics such as species richness (the number of unique species) and alpha diversity (local diversity within a habitat), as well as beta (diversity among habitats) and zeta diversity (higher-order diversity measures capturing shared species across multiple sites), is increasingly employed in conservation studies. Together, these metrics provide a comprehensive picture of biodiversity patterns and can elucidate the spatial turnover of species assemblages, helping to identify regions of high ecological uniqueness or vulnerability.</p> <p>Within this context, advanced modelling techniques like Generalized Dissimilarity Modelling (GDM) and its multi-site extension, Multi-Site Generalized Dissimilarity Modelling (MS-GDM), are powerful tools. GDM is a statistical framework that models compositional dissimilarity as a function of environmental and spatial gradients, effectively linking species turnover to ecological processes. MS-GDM expands upon this by incorporating multiple sites simultaneously, leveraging zeta diversity metrics to capture more complex spatial patterns and interactions across landscapes.  Species richness refers to the total number of unique species within a community or region. Alpha diversity captures within-site species diversity, while beta diversity measures differences in species composition between habitats or sites. Zeta diversity is an extension used in multi-site comparisons, which calculates species overlap across multiple locations, helping to capture patterns of similarity and dissimilarity in complex landscapes.</p> <p>Generalized Dissimilarity Modelling (GDM): GDM is a non-linear modelling approach for relating species turnover to spatial and environmental gradients, effectively capturing the complexity of species-environment relationships. Multi-Site Generalized Dissimilarity Modelling (MS-GDM): MS-GDM extends GDM for multi-site comparisons, particularly useful in understanding higher-order patterns of biodiversity through the incorporation of zeta diversity. This is some text.</p>"},{"location":"dissimilarity-cube/#objectives","title":"Objectives","text":"<ul> <li>Streamline Data Access and Preparation: Address the need for efficient automation of species occurrence and environmental data processing, reducing the manual effort and potential inconsistencies in ecological data collection.</li> <li>Enhance Species Co-occurrence and Compositional Analysis: Provide novel methods for quantifying co-occurrence patterns and compositional dissimilarities, filling the gap in scalable, standardized tools for analysing species interactions and biodiversity composition.</li> <li>Advance Bioregional Classification and Spatial Mapping: Introduce a robust framework for classifying regions based on ecological similarity, offering improved tools for delineating bioregions and capturing landscape-scale biodiversity patterns.</li> <li>Innovate Modelling and Prediction of Compositional Turnover: Utilize advanced multiscale models to quantify and predict compositional changes, addressing a critical need for understanding the drivers of biodiversity turnover and their interactions with environmental gradients.</li> <li>Assess Bioregional Shifts and Biodiversity Change: Develop new approaches for evaluating and visualizing shifts in bioregion boundaries and compositional changes under future scenarios, providing essential insights for conservation planning and ecosystem management in a changing climate. </li> </ul>"},{"location":"dissimilarity-cube/#methods","title":"Methods","text":"<p>Dissimilarity Workflow: The development of this R package aims to streamline and enhance biodiversity research by automating data access, pre-processing, and analysis, addressing key challenges faced in ecological studies. By integrating functions for species occurrence data retrieval, environmental data processing, co-occurrence analysis, and compositional turnover modelling, the package provides a comprehensive toolkit for exploring spatial patterns and ecological relationships. It is designed to be user-friendly, allowing researchers to quickly assess biodiversity metrics, classify bioregions, and model future changes under different environmental scenarios. Ultimately, this package supports efficient, repeatable, and scalable analyses, facilitating deeper insights into ecosystem dynamics and aiding conservation efforts in the face of global change.</p>"},{"location":"dissimilarity-cube/#data-access-and-preparation","title":"Data Access and Preparation","text":"<p>This section focuses on automating the retrieval and pre-processing of core data, including species occurrence and environmental variables. These data form the basis for further ecological analysis and model building.  Objective: Automate access and preparation of species and environmental data to support downstream biodiversity assessments.</p>"},{"location":"dissimilarity-cube/#species-occurrence-records","title":"Species Occurrence Records","text":"<p>Data will be obtained from i) local sources; ii) Global Biodiversity Information Facility (GBIF); iii) species occurrence cubes from B3.</p> <p>Automate access and preprocessing of species occurrence data from sources such as local databases, the Global Biodiversity Information Facility (GBIF), and species occurrence cubes. This involves assembling data on species distributions across specified taxonomic groups and regions, resulting in matrices that quantify species co-occurrence within locations.</p> <p><code>get_species</code>: Fetches and formats species occurrence data from various sources (e.g., local databases, GBIF), creating presence-absence or abundance matrices.  </p> <p></p> <p>Table x: Expected structure of species occurrence records in short format data frame.</p> site_id x (longitude) y (latitude) sp_name (species) pa (presence/absence) abund (abundance) 1 30.0 -20.0 Pieris brassicae 1 5 2 31.0 -21.0 Eutricha capensis 1 10 2 31.0 -21.0 Acraea horta 1 1 3 32.0 -22.0 Dixeia charina 1 2 3 32.0 -22.0 Pieris brassicae 1 4 3 32.0 -22.0 Acraea horta 1 12 <p>Table x: Expected structure of species occurrence records in long format data frame.</p> site_id x (longitude) y (latitude) sp_1 (pa/abund) sp_2 (pa/abund) sp_3 (pa/abund) sp_4 (pa/abund) 1 30.0 -20.0 1 0 0 0 2 31.0 -21.0 0 1 1 0 3 32.0 -22.0 1 0 1 1"},{"location":"dissimilarity-cube/#environmental-data","title":"Environmental Data","text":"<p>Environmental data are sourced from i) local sources, ii) WorldClim using <code>geodata</code>, iii) CHELSA using <code>climenv</code>, iv) Google Earth Engine using <code>rgee</code>, and v) additional biodiversity data using <code>mapme.biodiversity</code>. Automate access and preprocessing of environmental data using diverse sources (e.g., local records, WorldClim, CHELSA, GEE) to compile georeferenced environmental layers (e.g., climate, soil, topography) that are essential for understanding ecological drivers of species distributions.</p> <p><code>get_enviro</code>: Retrieves georeferenced environmental data (e.g., climate, soil) and clips it to the study area extent, making it compatible with species data.  </p> <p></p>"},{"location":"dissimilarity-cube/#data-formatting","title":"Data Formatting","text":"<p>Organizes the prepared data into structured data frames for easy access during analysis.</p> <p><code>format_df</code>: Organizes the prepared data into structured data frames for easy access during analysis:</p> <ul> <li>site_xy: Holds spatial coordinates of sampled sites.</li> <li>site_sp: Site-by-species matrix for biodiversity assessments.</li> <li>site_env: Site-by-environment matrix linking species and environmental data.</li> </ul> <p>Table x: Output structure of <code>site_xy</code>, which holds spatial coordinates of sampled sites.</p> site_id x (longitude) y (latitude) 1 30.0 -20.0 2 31.0 -21.0 3 32.0 -22.0 <p>Table x: Output structure of <code>site_sp</code>, the site-by-species matrix used for biodiversity assessments.</p> site_id sp_1 (pa/abund) sp_2 (pa/abund) sp_3 (pa/abund) sp_4 (pa/abund) sp_... (pa/abund) 1 1 0 0 0 1 2 0 1 1 0 1 3 1 0 1 1 1 <p>Table x: Output structure of <code>site_env</code>, the site-by-environment matrix linking species and environmental data.</p> site_id enviro_1 (variable) enviro_2 (variable) enviro_3 (variable) enviro_4 (variable) 1 30 0.123 1 1.45 2 20 0.812 5 8.82 3 10 0.021 4 2.040"},{"location":"dissimilarity-cube/#species-co-occurrence-and-compositional-analysis","title":"Species Co-occurrence and Compositional Analysis","text":"<p>This section provides tools to quantify species co-occurrence patterns and compositional dissimilarities, enabling insights into species interactions and biodiversity composition across landscapes. Objective: Quantify co-occurrence and compositional differences across locations to identify patterns of biodiversity and species interactions. Quantify co-occurrence patterns to assess the frequency with which species are found together across the landscape. This will yield a co-occurrence matrix and a raster layer illustrating spatial patterns in species associations. Quantify compositional dissimilarity to identify spatial variation in species composition across different locations. This analysis will produce dissimilarity matrices and spatially explicit rasters visualizing biodiversity turnover across the study area.</p> <p><code>calc_cooc</code>: Computes co-occurrence matrices and rasters to capture how often different species are found together, providing a foundation for analysing species associations.  </p> <p><code>calc_dissim</code>: Calculates dissimilarity metrics to measure variations in species composition and environmental properties across sites, highlighting areas of compositional turnover.</p>"},{"location":"dissimilarity-cube/#bioregional-classification","title":"Bioregional Classification","text":"<p>This section enables classification of landscapes into bioregions based on ecological and compositional similarities, helping identify areas that share common ecological traits. Objective: Classify regions based on compositional similarity to delineate bioregions, which reflect areas with unique ecological characteristics and species assemblages. Classify compositional similarities into unique bioregions by applying clustering algorithms to group locations with similar species compositions. The resulting bioregions offer insights into regions sharing similar ecological characteristics and species pools.</p> <p><code>map_bioreg</code>: Classifies the study area into distinct bioregions using clustering algorithms, with optional fuzzy clustering to assess stability across bioregion boundaries.</p>"},{"location":"dissimilarity-cube/#modelling-and-predicting-compositional-turnover","title":"Modelling and Predicting Compositional Turnover","text":"<p>This section includes tools for modelling compositional turnover as a function of geographic distance and environmental gradients, as well as predicting future compositional changes under different environmental scenarios. Objective: Model dissimilarity to understand factors driving compositional turnover and predict future changes due to environmental drivers, such as climate change. Model dissimilarity as a function of geographic distance and environmental conditions using MS-GDM, with dissimilarity values as the response variable and environmental layers as predictors. Model outputs will include coefficient estimates, standard errors, p-values, and R\u00b2 values, enhancing our understanding of biodiversity patterns. Predict future changes in species composition by extrapolating from MS-GDM results under projected environmental conditions (e.g., climate scenarios from CMIP5 or CMIP6). Later this will identify regions vulnerable to shifts in biodiversity and delineate areas where bioregion boundaries may alter in response to environmental change, offering a spatial forecast of biodiversity dynamics under future scenarios.</p> <p><code>model_dissim</code>: Uses a Multiscale Generalized Dissimilarity Model (MS-GDM) to relate compositional dissimilarity with geographic and environmental factors, providing coefficient estimates and model diagnostics.  </p> <p><code>predict_dissim</code>: Projects future compositional dissimilarities using MS-GDM results and future environmental scenarios to predict biodiversity changes under changing conditions.</p>"},{"location":"dissimilarity-cube/#bioregional-change-assessment","title":"Bioregional Change Assessment","text":"<p>This section provides tools to assess changes in bioregions and biodiversity composition over time, comparing current and future scenarios to identify areas vulnerable to shifts in ecological assemblages. Objective: Assess landscape-level shifts in biodiversity and bioregions under future environmental change scenarios, identifying potential regions of ecological transformation. Classify predicted future compositional similarities (under projected environmental conditions, e.g., climate scenarios from CMIP5 or CMIP6) into new set of unique bioregions by applying clustering algorithms to group locations with similar species compositions. Assess differences.</p> <p><code>calc_dissimDiff</code>: Computes differences in dissimilarity metrics between current and future projections, visualizing expected shifts in biodiversity composition. <code>map_bioregDiff</code>: Maps changes in bioregion boundaries over time, highlighting regions likely to experience significant shifts, losses, or new bioregional formations under future conditions.</p>"},{"location":"dissimilarity-cube/#results","title":"Results","text":"<p>In progress</p>"},{"location":"dissimilarity-cube/#discussion","title":"Discussion","text":"<p>In progress</p>"},{"location":"dissimilarity-cube/#conclusion","title":"Conclusion","text":"<p>In progress</p>"},{"location":"dissimilarity-cube/#data-availability-statement","title":"Data Availability Statement","text":"<p>In progress</p>"},{"location":"dissimilarity-cube/#acknowledgements","title":"Acknowledgements","text":"<ul> <li>National Institute for Theoretical and Computational Sciences (NITheCS)</li> </ul>"},{"location":"dissimilarity-cube/#references","title":"References","text":""},{"location":"dissimilarity-cube/#license","title":"License","text":"<p>This project is licensed under the MIT License MIT License - see the LICENSE.md file for details</p>"},{"location":"gee-py/","title":"Google Earth Engine","text":""},{"location":"gee-py/#getting-started-with-google-earth-engine","title":"Getting started with Google Earth Engine","text":"<p>The application of satellite derived datasets and geospatial analysis techniques in the fields of ecology and conservation has grown substantially over the last decade. With the emergence of cloud-based computing platforms that facilitate big data analysis, researchers, resource managers and remote sensing enthusiasts are now able to interrogate petabyte-scale datasets with ease.  </p> <p>Google Earth Engine (GEE) is a cloud-based computing platform which uses JavaScript commands to access and analyse planetary-scale geospatial datasets drawn from a variety of platforms. Through an internet-accessible application programming interface (API) and associated web-based interactive development environment (IDE), Google Earth Engine users are able to mine a massive collection of geospatial data for change detection, resource qualification and trend mapping on the Earth's surface like never before. The capacity of GEE to analyse remotely sensed data holds enormous potential for conservation planning and resource management.  </p> <p>This course aims to train students, researchers and practitioners in the application of Google Earth Engine in conservation science. Specifically, it seeks to familiarize participants with the basic operation of the GEE environment, focusing on visualization, analysis and automated detection of biological patterns and processes. </p> <p>The course will begin with a brief review of the fundamental theory behind remote sensing and geospatial analyses, followed by a series of tutorials.</p>"},{"location":"gee-py/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this practical you should be able to: - Understand the basic layout of Google Earth Engine platform (incl. the Code Editor). - Understand basic JavaScript syntax rules. - Find and import datasets into the code editor. - Inspect a dataset in the console. - Visualize datasets in the interactive map explorer. - Use simple functions. - Know where to find help.</p>"},{"location":"gee-py/#access-your-code-editor","title":"Access your code editor","text":"<p>The first step is to access the GEE code editor.  This can be done from the earth engine home page by going to platform \u2013&gt; Code Editor.  Alternatively, you can access it directly from https://code.earthengine.google.com/  Access the completed practical script here</p> <p> Take a look at the Google Earth Engine &gt;&gt; Guides &gt;&gt; Earth Engine Code Editor section for a nice description of different panels and tabs. </p>"},{"location":"gee-py/#create-your-own-repository-folders-and-files","title":"Create your own repository, folders and files","text":"<p>From the Scripts panel click NEW &gt;&gt; Repository or &gt;&gt; Folder or &gt;&gt; File Or if you already have a script open, click Save &gt;&gt; Save as..</p>"},{"location":"gee-py/#basic-javascript-syntax","title":"Basic JavaScript syntax","text":"<p>Let's start off with a simple \"Hello World\" exercise: <pre><code>print('Welcome to the world of GEE!');\nvar myMessage = 'GEE world - Sandra was here :)'; // Variable or object\nprint(myMessage);\n ```\n### Find and import datasets in the code editor\n***Draw your own***\nCreate your first import variables using the geometry tools. \nFor example, \"Add a marker\" or \"Draw a rectangle\". See the new 'geometry' variable added to the 'Imports' section? \nYou can 'Edit layer properties' e.g. the name or colour from \"Geometry Import\" or assets.\nIt is important to 'Exit' the 'Point drawing' and '+ new layer' to avoid creating a 'GeometryCollection' instead of a 'Point' geometry.\n![gee_screenshot3](assets/gee_1_4.png)\n\n### Create variables from known coordinates\nOr you can create your own variables using known coordinates. \n\n```js\nvar skukuza = ee.Geometry.Point([31.5912, -24.9947]);\nvar krugerAOI = ee.Geometry.Polygon([[[30.6821, -22.2315], [30.6821, -25.5061], \n                                      [32.1542, -25.5061], [32.1542, -22.2315]]]);&lt;/code&gt;&lt;button class=\"btn\" id=\"copy-button\" data-clipboard-target=\"#target2\"&gt;Copy&lt;/button&gt;\n</code></pre></p>"},{"location":"gee-py/#visualise-geometries","title":"Visualise geometries","text":"<p>To display these new variables on the map area below, you need to use the <code>Map.</code> commands. First zoom to a location on the map and then add the new variable as a layer with user defined display/legend properties.</p> <pre><code>// First center and zoom to a location on the map\n// There are different ways to center your map\nMap.setCenter(31.54, -23.96, 7); // Use the \"Inspector\" to click and get coords\nMap.centerObject(krugerAOI, 7); // Or using your geometry variable\n\n// Then add the variable to the map and change the colours\nMap.addLayer(krugerAOI, {color: 'green'}, 'Kruger Park');\nMap.addLayer(skukuza, {color: 'red'}, 'Skukuza Camp');&lt;/\n</code></pre>"},{"location":"gee-py/#find-and-import-online-gee-datasets","title":"Find and import online GEE datasets","text":"<p>To find GEE datasets, use the \u201cSearch places and datasets\u201d panel visible in the Code Editor or  browse datasets by satellite platform or keyword tags from the Earth Engine Catalog page.</p>"},{"location":"gee-py/#images","title":"Images","text":"<p>To import images from GEE you will use <code>ee.Image()</code>. There are two ways you can do this.  The easiest is to use the search function and then click Import to add the dataset to your Imports section. </p> <p>The second is to copy the Collection Snippet code and paste it into your script. Don't forget to make a new variable to hold the dataset.</p> <pre><code>var elevation = ee.Image('USGS/SRTMGL1_003');\nprint('Elevation variable info', elevation); // Print is your friend\nprint('Elevation data type', elevation.name()); // Prints data type\n</code></pre> <p>Once you've done that, if you hold your mouse over your new variable/code, you'll see a yellow message pop-up asking if you want to convert it to an import record. If you click Convert, the variable will be moved to the Imports section automatically. </p>"},{"location":"gee-py/#visualise-images","title":"Visualise images","text":"<p>To display images in your map you zoom to a location of interest and add then add the image as a layer but with more detailed display/legend properties. You can do this using the \"Visualization Parameters\" GUI or code it directly(see code box below). </p> <p><pre><code>// Center your map to specific area and zoom level\nMap.setCenter(31.54, -23.96, 7);\n// Play with the legend parameters\nMap.addLayer(elevation, {min: 0, max: 3500}, 'Elevation'); // Try without specific colours\nMap.addLayer(elevation, {min: 0, max: 3500, palette: ['blue','yellow','red']}, 'Elevation'); // Now add colour range\n// !NB! It matters what order you add variables to the map\n\n// What if we need a palette to display the variable better?\nvar eleVis = {\n  min: 0,\n  max: 1000,\n  palette: [\n    '141414', '383838', '808080', 'EBEB8F', 'F7D311', 'AA0000', 'D89382',\n    'DDC9C9', 'DCCDCE', '1C6330', '68AA63', 'B5C98E', 'E1F0E5', 'a975ba',\n    '6f198c'\n  ],\n};\n// Here are some guides to help you find colours\n// e.g. #DAF7A6,#FFC300,#FF5733,#C70039,#900C3F,#581845 \n// https://colorbrewer2.org/#type=sequential&amp;scheme=BuGn&amp;n=3\n// https://github.com/gee-community/ee-palettes\n\nMap.setCenter(31.54, -23.96, 7);\nMap.addLayer(elevation, eleVis, 'Elevation with eleVis'); // See how different your two layers look?\n</code></pre> </p> <p>Use the 'Inspector' to get \"Point\", \"Pixel\" and \"Object\" information. </p>"},{"location":"gee-py/#images-with-multiple-bands","title":"Images with multiple bands","text":"<p>WorldClim BIO Variables V1 Most of you will probably be familiar with WoldClim's Bioclimatic Variables. There are 19 different variables coded bio01 to bio19 e.g. bio01 = Annual mean | bio02 = Mean diurnal | bio03 = Isothermality (bio02/bio07) | bio04 = Temperature seasonality etc. </p> <p>To use one of these variables you need to select the appropriate band. For example \"Annual Mean Temperature\".</p> <pre><code>// Import WorldClim BIO Variables V1\nvar bio = ee.Image('WORLDCLIM/V1/BIO');\nvar amt = bio.select('bio01');\n\n// Same thing, less code\n// var amt = ee.Image('WORLDCLIM/V1/BIO').select('bio01'); \n\n// Your display/legend properties\nvar amtVis = {\n  min: -230.0,\n  max: 300.0,\n  palette: ['blue', 'purple', 'cyan', 'green', 'yellow', 'red'],\n};\n\n// Display the results on your map below\nMap.setCenter(31.54, -23.96, 2);\nMap.centerObject(krugerAOI, 7);\nMap.addLayer(amt, amtVis, 'Annual Mean Temperature');\nMap.addLayer(krugerAOI, {color: 'green'}, 'Kruger Park');\n// !NB! Remember it matters what order you add variables to the map\n</code></pre>"},{"location":"gee-py/#feature-collections","title":"Feature collections","text":"<p>Feature collections work in a similar way to image collections, although the display parameters and filtering conditions are slightly different. For example, let's display International Boundaries as polygons (i.e. vectors) </p> <pre><code>// Import the simplified International Boundary Polygons (LSIB 2017) \nvar countries = ee.FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\");\n\n// Your display properties\nvar cntVis = {\n    fillColor: 'b5ffb4',\n    color: '00909F',\n    width: 3.0,\n};\n\n// Add results to map\nMap.setCenter(23.63, 5.68, 2);\nMap.addLayer(countries, cntVis, 'World Borders');\n</code></pre>"},{"location":"gee-py/#filtering-feature-collections","title":"Filtering feature collections","text":"<p>Now to filter the features we need to know what column/field our contains the information we would like to filter for. In this case it's a \"string\" field named \"country_na\" as indicated in the \"TABLE SCHEMA\" in the figure above.</p> <pre><code>// Country boundaries filtered to Costa Rica\nvar costaRica = countries.filter(ee.Filter.eq('country_na', 'Costa Rica'));\nprint('eq Costa Rica', costaRica); // Remember, this returns info about our feature\n\n// Add results to map\nMap.centerObject(costaRica, 7);\nMap.addLayer(costaRica,{}, 'Costa Rica');\n\n// Country boundaries filtered to Costa Rica  and Colombia or a \"list\" of values\nvar costaColo = countries.filter(ee.Filter.inList('country_na',['Costa Rica','Colombia']));\nprint('costaColo data type',costaColo.name()); // Returns ComputedObject type\nprint('inList costaColo', costaColo); // Returns info about feature\nMap.centerObject(costaColo, 4);\nMap.addLayer(costaColo,{}, 'Costa Rica and Colombia');\n</code></pre> <p>Here is another example using polygons depicting the World Database on Protected Areas (WDPA) </p> <pre><code>// Import the WDPA polygons\nvar WDPA = ee.FeatureCollection('WCMC/WDPA/current/polygons');\n// WDPA boundaries filtered to 'Kruger' National Park' in South Africa\nvar kruger = WDPA.filter(ee.Filter.eq('ORIG_NAME', 'Kruger National Park'));\n// print('Kruger Info',kruger);\n\n// Add results to map\nMap.centerObject(kruger, 7);\nMap.addLayer(kruger,{fillColor:'ceea89',color:'789630',width:0.5}, 'Kruger National Park');\n</code></pre>"},{"location":"gee-py/#image-collections-filtered-by-dates-and-bands","title":"Image collections filtered by dates and bands","text":"<p>In many cases you will be dealing with image collections with a series of bands over a period of time. To filter for the date range you're interested in you will use the ee.Filter.date command. Let's test this using the 500m monthly burned area product from MODIS. </p> <pre><code>// Import the MODIS Burned Area Monthly Global 500m\nvar modis64 = ee.ImageCollection('MODIS/006/MCD64A1');\nvar modisBurn = modis64.select('BurnDate');\nvar burnArea = modisBurn.filter(ee.Filter.date('2018-01-01', '2018-12-31'));\nprint('burnArea Info long', burnArea);\n\n// Visual parameters for legend\nvar burnVis = {\n  min: 30.0,\n  max: 341.0,\n  palette: ['4e0400', '951003', 'c61503', 'ff1901'],\n};\n\n// Add results to map\nMap.centerObject(krugerAOI, 7);\nMap.addLayer(burnArea, burnVis, 'Areas Burnt Oct 2018');\n</code></pre>"},{"location":"gee-py/#simple-functions-and-single-images","title":"Simple functions and single images","text":"<p>There are many built-in functions you can use to process and analyse the different GEE data products. We will be going through a number of these in our different practical sessions but for now let's look at some simple ones to get you started. The most common is probably the .clip function, which we'll test on our elevation data from earlier.</p> <pre><code>// Clip the elevation data to your area of interest\nvar eleClip = elevation.clip(costaRica);\n\n// Add results to map\nMap.centerObject(costaRica, 7);\nMap.addLayer(eleClip, {min: 0, max: 350, palette: ['blue','yellow','red']}, \n                      'Costa Rica Elevation');\n</code></pre> <p>Let's try generating a slope from this new elevation variable using the built-in ee.Terrain.slope function.</p> <p><pre><code>// Generate a slope from the clipped SRTM elevation model\nvar slope = ee.Terrain.slope(eleClip);\n\n// Add results to map\nMap.centerObject(costaRica, 7);\nMap.addLayer(slope, {min: 0, max: 8}, 'Slope', false);\n// Display properties do not work for this area\n\n// Change the legend parameters \nvar slopeVis = {\n  min: 0,\n  max: 8,\n  palette: [\n    '#f7fcb9','#addd8e','#31a354','000000'\n  ],\n};\n\n// Add new results to map\nMap.addLayer(slope, slopeVis, 'Slope with palette');\n</code></pre> </p>"},{"location":"gee-py/#simple-functions-and-image-collections","title":"Simple functions and image collections","text":"<p>Applying functions to image collections starts to get a little trickier. For example, let's try summarise some Sentinel-2 imagery (Sentinel-2 MSI: MultiSpectral Instrument, Level-1C)and change our display properties at the same time. </p> <p><pre><code>// Import Sentinel-2 imagery\n// Filter the image collection based on several properties\nvar copCol = ee.ImageCollection(\"COPERNICUS/S2\")\n               .filter(ee.Filter.date('2018-01-01','2019-12-31')) // Filter date range\n               .filterBounds(krugerAOI); // Filter area\nprint('copCol Info', copCol);\n\n// Calculates a median value for all pixels over this time period                            \nvar cop2Med =  copCol.median();\n// Or you could use *.sort(\"CLOUD_COVERAGE_ASSESSMENT\")*\n// And them select the first image of the collection \n// i.e. the most cloud free, using *.first()* instead of .median()\n\n// Check output\nprint('Sentinel 2 image Info', cop2Med);\n\n// Add new results to map\nMap.setCenter(31.5975, -24.9945, 12);\n// Select Bands 4, 3 and 2 = red, green and blue bands to make a true-colour composite\n// Add this RGB composite to map, without defined parameters\nMap.addLayer(cop2Med, {bands:['B4','B3','B2']}, 'No defined vis parameters');\n// Results are rubbish\n</code></pre> </p> <pre><code>// Add the S2 value range from 0 to 3000, and try again\nMap.addLayer(cop2Med, {bands:['B4','B3','B2'], min:0, max: 3000}, 'True-colour');\n// You can also change the order of bands e.g. B8,B4,B3 = false-colour composite etc\nMap.addLayer(cop2Med, {bands:['B8','B4','B3'], min:0, max: 3000}, 'False-colour');\n// Here using the NIR band, this false-colour shows photosynthetically \n// active vegetation in bright red\n</code></pre> <p></p>"},{"location":"gee-py/#sharing-your-code-to-complete-the-practical-assignments","title":"Sharing your code to complete the practical assignments","text":"<p>To complete the practical exercise below you need to know how to share your scripts with us. Simply click on \"Get Link\" - the actual button NOT the dropdown arrow - Then click the \"Click to copy link\" button and paste that in an email. !NB! Please remember to add the prac number in the header. </p>"},{"location":"impact-indicators/","title":"Impact indicators","text":""},{"location":"impact-indicators/#specification-for-calculation-of-impact-indicators-of-alien-taxa","title":"Specification for calculation of impact indicators of Alien Taxa","text":"<p>This document demonstrate the computation of impact indicator of alien species using the <code>impact_indicator</code>. The <code>impact_indicator</code> feeds in species occurrence cube from the <code>b3gbi::process_cube</code> using <code>taxaFun</code> and processed Environmental Impact Classification of Alien Taxa (EICAT) impact score of species using <code>impact_cat</code>. The code in on GitHub repository https://github.com/mmyahaya/impact.indicator.</p>"},{"location":"impact-indicators/#task-53-indicators-on-impacts-of-alien-taxa-lead-sun","title":"Task 5.3: Indicators on impacts of alien taxa [Lead: SUN]","text":"<p>Integration of impacts with occurrence cubes and other projected cubes can provide estimates of current and potential future impacts of biological invasions. A standardised classification system has been developed for impacts of alien taxa (Blackburn et al. 2014, IUCN 2020) and data on impacts are publicly available in databases such as GRIIS. This task will integrate these data with biodiversity data cubes to demonstrate impact for specific case systems and study taxa, feeding into national indicators, impact of specific species, cumulative impact of several species on specific sites (Wilson et al. 2018), and impact risk (McGeoch et al. 2021). We can also provide estimates of invasion debt and forecast potential impacts spatially and temporally (Rouget et al.2016). This task will show how species traits can be incorporated into cubes to develop indicators.</p> <ul> <li>Nov 2023: M24 \u2013 Development of impact indicator workflow</li> <li>Oct 2024: M25 - Design code to calculate the IAS impact indicator</li> <li>Apr 2025: D5.3 \u2013 Indicators on impacts of alien taxa</li> </ul>"},{"location":"impact-indicators/#code-to-calculate-the-impact-indicator","title":"Code to calculate the impact indicator","text":"<p>The impact of invasive alien species is recognised as one of the leading drivers of biodiversity loss, significantly disrupting native ecosystems. This repository provides several types of impact indicator by integrating GBIF occurrences cube and the Environmental Impact Classification for Alien Taxa (EICAT) scoring system. Alien species causes impact at various magnitude, through different mechanisms and regions. This repository is a step towards automated impact indicator to track impact of alien species.</p>"},{"location":"impact-indicators/#authors","title":"Authors","text":"<ul> <li>Mukhtar Yahaya</li> <li>Sabrina Kumschick</li> <li>Sandra MacFadyen</li> <li>Pietro Landi</li> </ul> <p>See also the list of contributors who participated in this project.</p>"},{"location":"impact-indicators/#license","title":"License","text":"<p>This project is licensed under the MIT License MIT License - see the LICENSE.md file for details</p>"},{"location":"impact-indicators/#acknowledgments","title":"Acknowledgments","text":"<ul> <li>National Institute for Theoretical and Computational Sciences (NITheCS)</li> </ul>"},{"location":"invasibility-cube/","title":"Invasibility cube","text":""},{"location":"invasibility-cube/#specification-for-invasibility-cubes-and-their-production","title":"Specification for invasibility cubes and their production","text":"<p>This document presents the specification for \"invasibility cubes\u201d, to visualise invasion fitness and invasibility. It provides a workflow to visualise invasion fitness, using species occurrence data, Invasive Alien Species (IAS) lists, and species traits to calculate trait centrality, visualise trait dispersion, estimate interaction strength, and assess invasibility.</p>"},{"location":"invasibility-cube/#task-43-network-invasibility-cube-lead-sun","title":"Task 4.3: Network invasibility cube [Lead: SUN]","text":"<p>Develop a workflow to visualise invasion fitness, using species occurrence data, IAS lists, and species traits to calculate trait centrality, visualize trait dispersion, estimate interaction strength, and assess invasibility. Outputs include interaction strength matrices and community dynamics details under biological invasions.</p> <ul> <li>Dec 2024: M15 \u2013 Code design: Visualise trait dispersion to assess invasibility</li> <li>May 2025: M16 \u2013 Code test: Visualise trait dispersion to assess invasibility</li> </ul>"},{"location":"invasibility-cube/#introduction","title":"Introduction..","text":"<p>Develop a workflow to visualise invasion fitness, using species occurrence data, Alien Invasive Species (AIS) lists, and species traits to calculate trait centrality, visualise trait dispersion, estimate interaction strength, and assess invasibility. Outputs include interaction strength matrices and community dynamics details under biological invasions.</p>"},{"location":"invasibility-cube/#objectives","title":"Objectives","text":"<p>This workflow supports the work package deliverables for \"Visualising Invasion Fitness and Invasibility\". The workflow is designed to compute and visualise the invasion fitness and invasibility of ecological interaction networks. By leveraging species occurrence data, lists of invasive alien species (IAS), and species traits, the workflow enables the calculation of community invasibility and the identification of maximum-invasiveness traits (MITs). The workflow delivers outputs such as interaction strength matrices, community trait profiles, and regional maps of invasibility, thus providing crucial insights into ecological network stability and community openness. Below is an expanded description of the workflow used to achieve these objectives:</p>"},{"location":"invasibility-cube/#methods","title":"Methods","text":""},{"location":"invasibility-cube/#data-access-and-preparation","title":"Data Access and Preparation","text":"<p>This section focuses on automating the retrieval and pre-processing of core data, including species occurrence and environmental variables. These data form the basis for further ecological analysis and model building.  Objective: Automate access and preparation of species, trait and environment data to support downstream invasibility assessments.</p>"},{"location":"invasibility-cube/#species-occurrence-records","title":"Species Occurrence Records","text":"<p>Data will be obtained from i) local sources; ii) Global Biodiversity Information Facility (GBIF); iii) species occurrence cubes from B3.</p> <p>Automate access and preprocessing of species occurrence data from sources such as local databases, the Global Biodiversity Information Facility (GBIF), and species occurrence cubes. This involves assembling data on species distributions across specified taxonomic groups and regions, resulting in matrices that quantify species co-occurrence within locations.</p> <p><code>get_species</code>: Fetches and formats species occurrence data from various sources (e.g., local databases, GBIF), creating presence-absence or abundance matrices.  </p> <p>Table x: Expected structure of species occurrence records in short format data frame.</p> site_id x (longitude) y (latitude) sp_name (species) pa (presence/absence) abund (abundance) 1.0 1.0 1.0 Species A 1 5 2.0 1.0 1.0 Species B 0 0 3.0 1.0 1.0 Species C 1 2 <p>Table x: Expected structure of species occurrence records in long format data frame.</p> site_id x (longitude) y (latitude) sp_1 (pa/abund) sp_2 (pa/abund) sp_3 (pa/abund) sp_4 (pa/abund) Row 1 1.0 1.0 1.0 1.0 1.0 1.0 Row 2 1.0 1.0 1.0 1.0 1.0 1.0 Row 3 1.0 1.0 1.0 1.0 1.0 1.0"},{"location":"invasibility-cube/#species-traits","title":"Species Traits","text":"<p>Here the TRY database is used to link plant traits back to species records, enabling robust trait-based analyses of biodiversity. Managed by Future Earth and the Max Planck Institute, TRY is a global repository of standardized plant trait data. Version 6 includes over one million records for 2661 traits across 305,000 taxa. It integrates data from 700 datasets, providing global coverage. Open access (CC BY license) ensures transparency, facilitating research on biodiversity, ecosystem functions, and supporting dynamic global models of ecosystem responses to environmental change.</p> <p><code>dataGEN</code>: Leverages the TRY database to link plant traits back to species records.</p>"},{"location":"invasibility-cube/#environmental-data","title":"Environmental Data","text":"<p>Environmental data are sourced from i) local sources, ii) WorldClim using <code>geodata</code>, iii) CHELSA using <code>climenv</code>, and iv) additional biodiversity data using <code>mapme.biodiversity</code>. Automate access and preprocessing of environmental data using diverse sources (e.g., local records, WorldClim, CHELSA, GEE) to compile georeferenced environmental layers (e.g., climate, soil, topography) that are essential for understanding ecological drivers of species distributions.</p> <p><code>get_enviro</code>: Retrieves georeferenced environmental data (e.g., climate, soil) and clips it to the study area extent, making it compatible with species data.</p>"},{"location":"invasibility-cube/#data-formatting","title":"Data Formatting","text":"<p>Organizes the prepared data into structured data frames for easy access during analysis.</p> <p><code>format_df</code>: Organizes the prepared data into structured data frames for easy access during analysis:</p> <ul> <li>site_xy: Holds spatial coordinates of sampled sites.</li> <li>site_sp: Site-by-species matrix for biodiversity assessments.</li> <li>site_env: Site-specific environmental data provides contextual information about the conditions at each study location.</li> <li>sp_trait: Species-specific trait data essential for understanding how species traits influence interactions.</li> </ul> <p>Table x: Output structure of <code>site_xy</code>, which holds spatial coordinates of sampled sites.</p> site_id x (longitude) y (latitude) Site_1 31.50 -24.20 Site_2 31.51 -24.21 Site_3 31.52 -24.22 <p>Table x: Output structure of <code>site_sp</code>, the site-by-species matrix used for biodiversity assessments.</p> site_id sp_1 (pa/abund) sp_2 (pa/abund) sp_3 (pa/abund) sp_4 (pa/abund) sp_... (pa/abund) Site_1 1.0 1.0 1.0 1.0 1.0 Site_2 1.0 1.0 1.0 1.0 1.0 Site_3 1.0 1.0 1.0 1.0 1.0 <p>Table x: Output structure of <code>site_env</code>, the site-by-environment matrix linking species and environmental data.</p> site_id enviro_1 (variable) enviro_2 (variable) enviro_3 (variable) enviro_4 (variable) Site_1 1.0 1.0 1.0 1.0 Site_2 1.0 1.0 1.0 1.0 Site_3 1.0 1.0 1.0 1.0 <p>Table x: Output structure of <code>sp_trait</code>, the species-by-traits matrix used for understanding how species traits influence interactions.</p> site_id trait_1 (sp trait) trait_2 (sp trait) trait_3 (sp trait) trait_4 (sp trait) Site_1 1.0 1.0 1.0 1.0 Site_2 1.0 1.0 1.0 1.0 Site_3 1.0 1.0 10.0 1.0"},{"location":"invasibility-cube/#community-trait-profiles","title":"Community Trait Profiles","text":"<p>In progress...</p>"},{"location":"invasibility-cube/#functional-dissimilarity","title":"Functional Dissimilarity","text":"<p>In progress...</p>"},{"location":"invasibility-cube/#interaction-strength","title":"Interaction Strength","text":"<p>In progress...</p>"},{"location":"invasibility-cube/#invasibility-assessment-and-prediction","title":"Invasibility Assessment and Prediction","text":"<p>In progress...</p>"},{"location":"invasibility-cube/#results","title":"Results","text":"<p>In progress...</p>"},{"location":"invasibility-cube/#discussion","title":"Discussion","text":"<p>In progress</p>"},{"location":"invasibility-cube/#conclusion","title":"Conclusion","text":"<p>In progress</p>"},{"location":"invasibility-cube/#data-availability-statement","title":"Data Availability Statement","text":"<p>In progress</p>"},{"location":"invasibility-cube/#acknowledgements","title":"Acknowledgements","text":"<ul> <li>National Institute for Theoretical and Computational Sciences (NITheCS)</li> </ul>"},{"location":"invasibility-cube/#references","title":"References","text":"<p>In progress...</p>"},{"location":"invasibility-cube/#license","title":"License","text":"<p>This project is licensed under the MIT License MIT License - see the LICENSE.md file for details</p>"},{"location":"invasibility-cube/#acknowledgments","title":"Acknowledgments","text":"<ul> <li>National Institute for Theoretical and Computational Sciences (NITheCS)</li> </ul>"},{"location":"resources/","title":"Other Online Resources","text":""},{"location":"resources/#biodiversity-monitoring-and-modelling","title":"Biodiversity monitoring and modelling","text":"<p>A general workflow for analysis of primary biodiversity data</p> <p>A brief tutorial on running Maxent in R</p>"},{"location":"science-i/","title":"Science-i","text":"<p>Science-i: Bridging Worlds Competition 2024 Our proposal below aligns with the competition's focus on innovative, impactful research in forest science, leveraging advanced computational resources and global biodiversity databases to address critical ecological challenges.</p>"},{"location":"science-i/#zetaforests-unveiling-higher-order-turnover-and-co-occurrence-of-global-forests","title":"ZetaForests: Unveiling higher-order turnover and co-occurrence of global forests","text":"<p>Our project, ZetaForests, aims to elucidate the complex interplay of compositional, structural, and functional turnover of biodiversity between local communities across global forests, leveraging Multisite Generalized Dissimilarity Modelling (MS-GDM) of Zeta Diversity (Fig. 1). Zeta diversity offers a set of metrics for complete biodiversity partitioning, unlike the concept of Alpha and pairwise Beta metrics. This novel approach will address why African tropical forests exhibit lower species richness compared to their counterparts in Asia and the Amazon, and why traditional metabolic rate theories fail to explain species richness in lower latitude tropics. By integrating extensive biodiversity datasets and employing advanced computational analyses, this project aims to uncover the underlying mechanisms of forest biodiversity maintenance and explain the decay of biodiversity similarity of regional species along a prevalence continuum (from rare - low prevalence, to widespread - high prevalence). The project hypothesizes that unique historical, ecological, and climatic factors in African tropical forests contribute to these anomalies, compounded by significant data gaps.</p> <p></p>"},{"location":"science-i/#project-impact-incl-current-and-future-use-in-science-and-society","title":"Project impact incl. current and future use in science and society","text":"<p>ZetaForests aims to redefine ecological research and conservation strategies by providing novel insights into forest biodiversity. This advancement will enable the creation of improved ecosystem management strategies, boosting forest resilience and sustainability, such as the development of crucial metrics for invasibility and openness. The project's methodologies and findings could serve as a blueprint for similar studies in other biomes, fostering a more comprehensive understanding of global biodiversity and guiding policy decisions for biodiversity conservation.</p>"},{"location":"science-i/#knowledge-gap-explained","title":"Knowledge gap explained","text":"<p>Despite extensive research, the comprehensive understanding of global forest biodiversity patterns remains elusive, particularly the intricate species interactions and the full spectrum of biodiversity (compositional, structural, and functional). The project aims to fill these gaps by leveraging underutilized MS-GDM and Zeta Diversity metrics to provide a more nuanced understanding of forest biodiversity, particularly addressing the anomalies observed in African tropical forests. More specifically, we will focus on 1) Forest turnover: Using MS-GDM (i.e. dissimilarity) of zeta to uncover assembly mechanisms that may explain the decay of compositional/functional/structural dissimilarity along ecological and geographic distance, for different zeta orders; and 2) Forest co-occurrence: Using the transpose of MS-GDM (i.e. similarity) to explain higher-order co-occurrence of tree species by their traits and phylogeny, potentially identifying species guilds and interactions using this unique global dataset of local forest community surveys.</p>"},{"location":"science-i/#project-timeline","title":"Project timeline","text":"<ul> <li>Months 1-6: Development of analytical frameworks and data compilation.</li> <li>Months 7-12: Application of MS-GDM and zeta diversity - analyses; initial dashboard development.</li> <li>Months 13-18: In-depth biodiversity pattern analysis; - dashboard refinement.</li> <li>Months 19-24: Synthesis of findings; publication in Nature; -release of the interactive dashboard.</li> </ul>"},{"location":"sdm-r/","title":"Species Distribution Modelling","text":""},{"location":"sdm-r/#an-introduction-to-species-distribution-modeling-and-environmental-data-integration-in-r","title":"An Introduction to Species Distribution Modeling and Environmental Data Integration in R","text":"<p>Species Distribution Modeling (SDM) is a powerful method for predicting the potential distribution of species across different landscapes by analysing relationships between known species occurrences and environmental variables. SDMs are essential in conservation planning, allowing researchers and practitioners to identify critical habitats, model species response to environmental changes, and predict impacts of climate change. This tutorial makes extensive use of data from the Global Biodiversity Information Facility (GBIF), an international network and data platform providing open access to biodiversity occurrence records contributed by museums, scientific institutions, and citizen scientists worldwide. GBIF serves as a vital resource for biodiversity research, enabling users to access large datasets on species occurrences and environmental attributes.</p> <p>Generalized Dissimilarity Modelling (GDM) is an advanced method for examining patterns of ecological turnover across environmental gradients. GDM is especially useful for mapping and visualising dissimilarity in species composition and diversity across spatial scales. It helps identify the role of environmental variables and geographic distance in driving species distribution patterns. Multi-Site Generalized Dissimilarity Modelling (MS-GDM) is an extension of GDM designed for analysing multiple sites simultaneously, providing deeper insights into how communities differ across locations and allowing comparisons across varied environmental conditions.</p> <p>Zeta Diversity is an approach for examining biodiversity across multiple sites, quantifying the commonness and rarity of species shared between them. Zeta diversity goes beyond traditional pairwise comparisons, allowing researchers to analyse the turnover and nestedness of species composition across multiple locations, offering a robust tool for biodiversity assessment in complex landscapes.</p> <p>In this tutorial, participants will learn to use these techniques in R, combining occurrence and environmental data for SDM, MS-GDM, and Zeta Diversity analyses to support species conservation and ecosystem management. </p>"},{"location":"sdm-r/#load-libraries","title":"Load libraries","text":"<pre><code># See https://rsh249.github.io/bioinformatics/spatial.html\n\n# install.packages(\"ENMeval\", INSTALL_opts=\"--no-multiarch\")\nlibrary(dismo) # Species Distribution Modeling tools\nlibrary(raster) # R tools for GIS raster files &gt;&gt;&gt; USE terra{} instead\nlibrary(spocc) # Access species occurrence data from GBIF/iNaturalist\nlibrary(ENMeval) # Tuning SDMs\n# library(mapr) # Quick mapping tools\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(geodata)\nlibrary(sfheaders)\n\nlibrary(dplyr)\nlibrary(tidyr)        ## spread()\nlibrary(reshape2)     ## dcast(), melt()\n\n# library(gdm)\nlibrary(zetadiv)\n</code></pre>"},{"location":"sdm-r/#download-worldclim-climate-data","title":"Download WorldClim climate data","text":"<p><pre><code># Download the WorldClim Bioclimatic variables for the world at a 10 arc-minute resolution\nbio_10m = getData('worldclim', var='bio', res=10, path='D:/Workshops/Zeta_MSGDM/Data') # Set your own path directory\n\n# Use geodata package instead\nbio_10m_rsa = worldclim_country(\"South Africa\", var=\"tmin\", path='D:/Workshops/Zeta_MSGDM/Data')\n\nsummary(bio_10m)\nbio_10m[[1]] #BIO1 = Annual Mean Temperature\n</code></pre> Read descriptions/definitions of Bioclimatic variables.</p>"},{"location":"sdm-r/#crop-to-your-area-of-interest","title":"Crop to your area of interest","text":"<pre><code># Define 'extent' of boundary\n# South Africa\nrsa_ext = extent(16, 33, -35, -22)\n\n# Crop Bioclimatic variables to extent of South African boundary\nrsaExt_bio_10m = crop(bio_10m, rsa_ext)\nplot(rsaExt_bio_10m[[1]]) # Basic plotting \n</code></pre>"},{"location":"sdm-r/#or-crop-to-country-borders","title":"Or crop to country borders","text":"<pre><code># Using GADM (gives a SpatialPolygonsDataFrame)\nrsa = getData('GADM', country='South Africa', level=0, path='D:/Workshops/Zeta_MSGDM/Data')\n# rsa = sf::st_as_sf(rsa)\n\n# OR use geodata instead\n# rsa = gadm(country=\"ZA\", level=1, path='D:/Workshops/Zeta_MSGDM/Data') # or path=tempdir()\n# Use country_codes() to find correct code\n# cc = country_codes()\n# View(cc)\n\n# Basic National map\nggplot()+\n  geom_sf(data=sf::st_as_sf(rsa))+\n  ggtitle(\"South Africa\")\n</code></pre> <pre><code># Crop Bioclimatic variables to South African border\nrsa_bio_10m = crop(bio_10m, rsa)\nplot(rsa_bio_10m[[1]]) # See result\n\n# OR use geodata package instead\n# rsa_bio_10m = worldclim_country(\"South Africa\", var=\"tmin\", path='D:/Workshops/Zeta_MSGDM/Data')\n</code></pre>"},{"location":"sdm-r/#extract-raster-values-to-points","title":"Extract raster values to points","text":"<pre><code># Create 100 random points across South Africa\nrandom_pts = spsample(rsa, n=100, type=\"random\")    \n\n# See randomly generate points on RSA map\nplot(rsa_bio_10m[[1]])\nplot(random_pts, add=T)\n\n# Extract data to points\nbio_values_1 = extract(rsa_bio_10m, random_pts)\n\n# Use cbind.data.frame to get results as data.frame\nbio_values_df = cbind.data.frame(coordinates(random_pts), bio_values_1)\nhead(bio_values_df)\n</code></pre>"},{"location":"sdm-r/#use-your-own-tabular-data","title":"Use your own tabular data","text":"<pre><code># Read directly from csv file\nall_lepidoptera.sf = st_as_sf(read.csv('D:/Workshops/Zeta_MSGDM/Data/0097482-230224095556074.csv'), coords = c(\"x\", \"y\"), crs = 4326)  \nplot(all_lepidoptera.sf['family'])\n\n###############################################################################\n# EXTRACT RASTER DATA TO POINT LOCALITIES\n# Extract raster value by points\nlepidop_enviro = raster::extract(rsa_bio_10m, all_lepidoptera.sf)\nlepidop_enviro\n# Combine raster values with point and save as a CSV file.\nlepidop_enviro.ptData = cbind(all_lepidoptera.sf, lepidop_enviro)\n# Check output\nnames(lepidop_enviro.ptData)\nhead(lepidop_enviro.ptData)\n</code></pre>"},{"location":"sdm-r/#get-data-from-gbif","title":"Get data from GBIF","text":"<p>See https://poldham.github.io/abs/gbif.html First sign-up for a free account here. <pre><code>library(dplyr)\nlibrary(readr)  \nlibrary(rgbif) # for occ_download\n</code></pre></p> <pre><code># fill in your gbif.org credentials \nuser = \"xxxxxx\" # your gbif.org username \npwd = \"xxxxxx\" # your gbif.org password\nemail = \"xxxx@xxxxx\" # your email\n</code></pre> <p>The main functions related to downloads are: <code>occ_download()</code>: start a download on GBIF servers. <code>occ_download_prep()</code>: preview a download request before sending to GBIF. <code>occ_download_get()</code>: retrieve a download from GBIF to your computer. <code>occ_download_import()</code>: load a download from your computer to R.  </p> <pre><code>gbif_download = occ_data(scientificName='Lepidoptera',\n                         country='ZA',\n                         hasCoordinate=TRUE,\n                         hasGeospatialIssue=FALSE,\n                         limit=500)\nlepidoptera.df = as.data.frame(gbif_download$data)\nhead(lepidoptera.df)\n\nlepidop.df = lepidoptera.df[,c(1,3,4,16,31:33,42:46)]\n# head(lepidop.df)\n\nlepidop.sf = st_as_sf(lepidop.df, coords = c(\"decimalLongitude\", \"decimalLatitude\"), crs = 4326)\nplot(lepidop.sf['stateProvince'])\n</code></pre>"},{"location":"sdm-r/#citing-your-download","title":"Citing your download","text":"<p>If you end up using your download in a research paper, you will want to cite the download\u2019s DOI. Please see these citation guidelines for properly citing your download. When using this dataset please use the following citation:  GBIF.org (16 March 2023) GBIF Occurrence Download https://doi.org/10.15468/dl.uvu2qm</p>"},{"location":"sdm-r/#working-with-species-occurence-and-environmental-data-tables","title":"Working with species occurence and environmental data tables","text":"<pre><code># CONVERT TO DATAFRAME\n# all_lepidoptera.df = as.data.frame(all_lepidoptera.sf)\nall_lepidoptera.df = as.data.frame(cbind(all_lepidoptera.sf, st_coordinates(all_lepidoptera.sf)))[,-11]\nhead(all_lepidoptera.df) \n\n# lepidop_enviro.df = as.data.frame(lepidop_enviro.ptData)\nlepidop_enviro.df = as.data.frame(cbind(lepidop_enviro.ptData, st_coordinates(lepidop_enviro.ptData)))[,-30]\nhead(lepidop_enviro.df)\n\n# OR use sfheaders{}\n# lepidop_enviro.df = sf_to_df(lepidop_enviro.ptData, fill=TRUE)\n# head(lepidop_enviro.df)\n# str(lepidop_enviro.df)\n# summary(lepidop_enviro.df)\n</code></pre> <pre><code># SET COLUMN FORMATS\nlepidop_enviro.df$nameF = as.factor(lepidop_enviro.df$scientific)\nlepidop_enviro.df$dateT = as.Date(lepidop_enviro.df$date)\nhead(lepidop_enviro.df)\n\n# Create unique SITE IDs\nlepidop_enviro.df$unqIDF = as.factor(as.integer(as.factor(paste(lepidop_enviro.df$X,lepidop_enviro.df$Y, sep='_'))))\nhead(lepidop_enviro.df)\nstr(lepidop_enviro.df)\n</code></pre>"},{"location":"sdm-r/#get-your-table-into-the-right-format","title":"Get your table into the right format","text":"<pre><code># str(lepidop_enviro.df)\nhead(lepidop_enviro.df)\n\nlepidop_enviro.pa =lepidop_enviro.df %&gt;%\n  group_by(unqIDF, across(28:29), nameF, across(9:27)) %&gt;%\n  tally() %&gt;%\n  spread(nameF, n, fill=0)\nhead(lepidop_enviro.pa)\n# View(lepidop_enviro.pa)\n</code></pre>"},{"location":"sdm-r/#multi-site-generalised-dissimilarity-modelling-for-a-set-of-environmental-variables-and-distances","title":"Multi-site generalised dissimilarity modelling for a set of environmental variables and distances","text":""},{"location":"sdm-r/#how-to-compute-compositional-turnover-using-zeta-diversity","title":"How to Compute Compositional Turnover Using Zeta Diversity","text":"<p>Using zetadiv: https://rdrr.io/cran/zetadiv <pre><code>lepidop_enviro.pa_noNA = lepidop_enviro.pa[complete.cases(lepidop_enviro.pa), ] \nSitexy = as.data.frame(lepidop_enviro.pa_noNA[,1:3])\n# xy = st_as_sf(Sitexy, coords = c(\"X\", \"Y\"), crs = 4326)\nxy = as.data.frame(lepidop_enviro.pa_noNA[,2:3])\n\nenvRast = rsa_bio_10m\nenvTab = as.data.frame(lepidop_enviro.pa_noNA[,c(1:22)])\nsppTab = as.data.frame(lepidop_enviro.pa_noNA[,c(1:3,23:1109)])\n\n# envRast\n# str(envTab) # 5430 obs(sites) of  20 variables(enviro)\n# str(sppTab) # 5430 obs(sites) of  1088 variables(species)\n\n# ##site-species, table-table\n# exFormat1a = formatsitepair(sppTab, 1, siteColumn=\"unqIDF\", XColumn=\"X\", YColumn=\"Y\", predData=envTab)\n# exFormat1a\n# \n# ##site-species, table-raster\n# exFormat1b = formatsitepair(sppTab, 1, siteColumn=\"unqIDF\", XColumn=\"X\", YColumn=\"Y\", predData=envRast)\n# exFormat1b\n# \n# # plot(exFormat1b, plot.layout=c(2,3))\n# plot(exFormat1b[[1]])\n</code></pre></p> <pre><code># OR USE tidyr\nlong = sppTab %&gt;%\n  pivot_longer(!c(unqIDF,X,Y), names_to = \"nameF\", values_to = \"value\")\n</code></pre> <pre><code># Dealing with biases associated with presence-only data\n#--------------------------------------\n# weight by site richness\n# long[complete.cases(long), ]\n\ngdmTab = formatsitepair(long, bioFormat=2, XColumn=\"X\", YColumn=\"Y\",abundColumn='value',\n                         sppColumn=\"nameF\", siteColumn=\"unqIDF\", predData=envTab)\n\ngdmTab.rw = formatsitepair(long, bioFormat=2, XColumn=\"X\", YColumn=\"Y\",\n                            sppColumn=\"nameF\", siteColumn=\"unqIDF\",abundColumn='value',\n                            predData=envTab, weightType=\"richness\")\n# weights based on richness (number of species records)\ngdmTab.rw$weights[1:5]\n\n# remove sites with &lt; 10 species records\ngdmTab.sf = formatsitepair(long, bioFormat=2, XColumn=\"X\", YColumn=\"Y\",\n                            sppColumn=\"nameF\", siteColumn=\"unqIDF\",abundColumn='value',\n                            predData=envTab, sppFilter=10)\n</code></pre>"},{"location":"sdm-r/#gdm-generalized-dissimilarity-modeling","title":"<code>gdm</code>: Generalized Dissimilarity Modeling","text":"<p>Read more about <code>gdm</code> analysis here</p> <pre><code>gdm.1 = gdm(gdmTab.sf, geo=T)\n#summary(gdm.1)\nstr(gdm.1)\n\n# gdm plots\n#--------------------------------------------------------\nlength(gdm.1$predictors) # get idea of number of panels\nplot(gdm.1, plot.layout=c(4,3))\n\ngdm.1.splineDat = isplineExtract(gdm.1)\nstr(gdm.1.splineDat)\n\npar(mfrow=c(1,1))\nplot(gdm.1.splineDat$x[,\"Geographic\"], gdm.1.splineDat$y[,\"Geographic\"], lwd=3,\n     type=\"l\", xlab=\"Geographic distance\", ylab=\"Partial ecological distance\")\n</code></pre> <pre><code>zeta.ispline = Zeta.msgdm(sppTab[,c(4:1088)], envTab[,c(4:20)], xy, order=2,\n                          rescale = TRUE,\n                          rescale.pred = TRUE,\n                          method = \"mean\",\n                          normalize = \"Jaccard\",\n                          reg.type = \"ispline\",\n                          sam = 100)\n\n# zeta.ispline.r = Return.ispline(zeta.ispline, envTab[,c(4:20)], distance = TRUE)\n# zeta.ispline.r\n\ndev.new()\nPlot.ispline(msgdm = zeta.ispline, data.env = envTab[c(4:20)], distance = TRUE)\n</code></pre>"},{"location":"spatial-r/","title":"Spatial Data in R","text":""},{"location":"spatial-r/#an-introduction-to-spatial-data-analysis-in-r","title":"An Introduction to Spatial Data Analysis in R","text":"<p>Spatial analysis is a cornerstone of conservation ecology, providing insights into biodiversity patterns, habitat suitability, and landscape connectivity, all crucial for effective conservation planning. By using spatial data, ecologists can visualise, quantify, and model species distributions and environmental changes across landscapes, aiding in habitat protection and management strategies.</p> <p>R offers a comprehensive suite of tools for spatial data manipulation, analysis, and visualisation, allowing researchers to seamlessly integrate, process, and analyse large datasets. In this tutorial, participants will learn to handle vector and raster data, project datasets, and perform essential geospatial transformations and analyses. Through practical exercises, users will gain the skills to harness R\u2019s capabilities for ecological and conservation applications, laying the groundwork for more complex spatial analyses and modeling in conservation ecology.</p>"},{"location":"spatial-r/#useful-online-resources","title":"Useful online resources","text":"<p>Fundamentals of Spatial Analysis in R Spatial Data Science with R and <code>terra</code> Handling spatial data in R #3 Geocomputation with R Using Spatial Data with R </p>"},{"location":"spatial-r/#install-packages","title":"Install packages","text":"<pre><code>install.packages(c('sf','terra','spData','sp','rgdal','raster','rasterVis'))\ninstall.packages('spDataLarge', repos = 'https://nowosad.r-universe.dev')\n</code></pre>"},{"location":"spatial-r/#load-packages","title":"Load packages","text":"<pre><code>library(sf)           # classes and functions for vector data\nlibrary(terra)        # classes and functions for raster data\nlibrary(spData)       # load geographic data\nlibrary(spDataLarge)  # load larger geographic data\n\nlibrary(sp)\nlibrary(rgdal)\n# library(tmap)\n\nlibrary(raster)\nlibrary(rasterVis)\n\nlibrary(tidyr)\nlibrary(ggplot2)\n\nlibrary(tmap)\nlibrary(dplyr)\n</code></pre>"},{"location":"spatial-r/#set-your-working-directory","title":"Set your working directory","text":"<pre><code>#You will need to set your own working directory\nsetwd('D:/Students/VictoriaO')\n# setwd('D:\\\\Students\\\\VictoriaO') #Same thing\n</code></pre>"},{"location":"spatial-r/#objectives-of-this-tutorial","title":"Objectives of this tutorial","text":"<ul> <li>Read in vector data using the sp and sf packages.</li> <li>Convert between the sp and sf data models.</li> <li>Define and transform datums and projections for vector data.</li> <li>Access and work with attribute data associated with vector features.</li> <li>Read in raster data using the raster package.</li> <li>Define and transform datums and projections for raster data.</li> </ul>"},{"location":"spatial-r/#vector-data","title":"Vector data","text":""},{"location":"spatial-r/#points-lines-polygons","title":"Points - Lines - Polygons","text":"<pre><code>class(world)\nworld\nnames(world)\nplot(world)\n\nhead(data.frame(world))\nnames(world[3:6])\nplot(world[3:6])\n\nplot(world[\"lifeExp\"])\nsummary(world[\"lifeExp\"])\n\n#Subset\n(world_mini = world[1:2, 1:3])\nplot(world_mini['name_long'])\n\n(world_africa = world[world$continent == \"Africa\", ])\nplot(world_africa)\nplot(world_africa[\"lifeExp\"])\n\nplot(world[\"pop\"], reset = FALSE)\nplot(world_africa[\"lifeExp\"], add = TRUE, alpha=0.5)\n</code></pre>"},{"location":"spatial-r/#understanding-projections","title":"Understanding projections","text":"<p>Read more from epsg.io</p> <pre><code>st_crs(world)\nplot(world[,1])\n\n# EPSG:3395 is WGS 84 / World Mercator\nworld.tm = st_transform(world, 3395)\nst_crs(world.tm)\nplot(world.tm[,1])\nplot(world[,1])\n#................................\n\n#Calculate areas\nRSA = world[world$name_long == \"South Africa\", ]\nplot(RSA[,1])\n\nst_area(RSA) # requires the s2 package in recent versions of sf\n#&gt; 1.216401e+12 [m^2] # output is in units of square meters (m2)\nst_area(RSA) / 1000000\n#&gt; 1 216 401 [m^2] # square kilometres (km2)\n# units::set_units(st_area(RSA), km^2)\n#&gt; 1 216 401 [km^2] 1,221 million km\u00b2 #https://en.wikipedia.org/wiki/South_Africa\n</code></pre>"},{"location":"spatial-r/#where-to-find-free-gis-data-layers","title":"Where to find free GIS data layers","text":"<p>https://mapcruzin.com/ https://data.humdata.org/dataset/ https://africaopendata.org/ https://egis.environment.gov.za/data_egis/ https://bgis.sanbi.org/SpatialDataset https://dataportal-mdb-sa.opendata.arcgis.com/ http://geoportal.icpac.net/ </p>"},{"location":"spatial-r/#add-your-own-data-layers","title":"Add your own data layers","text":"<pre><code>#Create your own points\n(pnts = rbind(c(-79, 36), c(-101, 41), c(-80, 27), c(-91, 52), c(-68, 42)))\n(pnts.sp = SpatialPoints(pnts))\nsummary(pnts.sp)\n\n#Plot those on map produced in 116\nplot(pnts.sp)\nplot(world_africa[\"lifeExp\"])\nplot(pnts.sp, add=T, col='white')\n\n#Don't forget to add a coordinate system\nis.projected(pnts.sp)\nproj4string(pnts.sp) =CRS('+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs')\nproj4string(pnts.sp) =CRS('+init=epsg:4326') #Different way to do same thing\nsummary(pnts.sp)\n</code></pre> <pre><code>#Read in data (shapefiles) *Data from getData {raster} \n#Using rgdal\n(rsa_country = readOGR(dsn = 'Data', layer = 'gadm36_ZAF_0'))\nplot(rsa_country)\n(rsa_provinces = readOGR(dsn = 'Data', layer = 'gadm36_ZAF_1'))\nplot(rsa_provinces)\n(rsa_district = readOGR(dsn = 'Data', layer = 'gadm36_ZAF_2'))\nhead(rsa_district); plot(rsa_district)\n\nplot(rsa_country)\nplot(rsa_provinces)\nplot(rsa_district)\n\n#Using sf\n(rsa_country_sf = st_read('Data/gadm36_ZAF_0.shp'))\n(rsa_provinces_sf = st_read('Data/gadm36_ZAF_1.shp'))\n(rsa_district_sf = st_read('Data/gadm36_ZAF_2.shp'))\nplot(rsa_country_sf[,1])\n</code></pre>"},{"location":"spatial-r/#convert-spdf-to-sf","title":"Convert SPDF to SF","text":"<p><pre><code>#You will need to set your own working directory. \nrsa_country #SpatialPolygonsDataFrame\nrsa_country_sf #Simple feature collection with 1 feature and 2 fields. Geometry type: MULTIPOLYGON\nrsa_country_sp = readOGR(dsn = 'Data', layer = 'gadm36_ZAF_0')\nrsa_country_sf = st_read('Data/gadm36_ZAF_0.shp')\n\n(rsa_country_sp_from_sf = as(rsa_country_sf, Class='Spatial'))\n(rsa_country_sf_from_sp = st_as_sf(rsa_country_sp))\n</code></pre> <pre><code>#Read in table of coordinates and create points\nwdpa.df = read.csv('Data/WDPA_Africa.csv')\nhead(wdpa.df)\nstr(wdpa.df) #'data.frame': 2411 obs. of  19 variables:\nnames(wdpa.df)\n\n(wdpa.sp = SpatialPointsDataFrame(wdpa.df[,3:4], wdpa.df[,c(5,7,16,19)], \n                                  proj4string=CRS('+init=epsg:4326'))) #SpatialPointsDataFrame\nplot(wdpa.sp)\n\nwdpa.sf = st_as_sf(wdpa.df, coords = c(\"Longitude\", \"Latitude\"), crs = 4326)\nwdpa.sf  \nplot(wdpa.sf['NAME'])\n</code></pre></p>"},{"location":"spatial-r/#more-about-coordinate-systems","title":"More about coordinate systems","text":"<pre><code>st_crs(rsa_country_sf)\n(proj_info = st_crs(rsa_country_sf))\n(proj_info_proj4 = as.vector(proj_info$proj4string))\n\nst_crs(rsa_country_sf) = NA\nst_crs(rsa_country_sf)\n\nst_crs(rsa_country_sf) = '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs'\nst_crs(rsa_country_sf)\n\nst_crs(rsa_country_sf) = NA\nst_crs(rsa_country_sf)\n\nst_crs(rsa_country_sf) = 4326\nst_crs(rsa_country_sf)\n#................................\n\nrsa_country_tm = st_transform(rsa_country_sf, crs=3395)\nst_crs(rsa_country_tm)\n</code></pre>"},{"location":"spatial-r/#save-vector-data-to-local-drive","title":"Save vector data to local drive","text":"<pre><code>writeOGR(obj=rsa_district, dsn='Data', \n         layer='rsa_district2', driver='ESRI Shapefile')\n\nst_write(rsa_district_sf, 'Data/rsa_country_tm.shp')\n</code></pre>"},{"location":"spatial-r/#convert-center-points-and-then-write-to-local-drive","title":"Convert center points and then write to local drive","text":"<pre><code>(rsa_district_pts = st_centroid(rsa_district_sf, of_largest = TRUE))\nplot(rsa_district_pts)\nplot(rsa_district_sf)\nst_write(rsa_district_pts, 'rsa_district_pts2.shp', layer_options = 'GEOMETRY=AS_XY')\n</code></pre>"},{"location":"spatial-r/#raster-data","title":"Raster data","text":""},{"location":"spatial-r/#raster-data-stucture","title":"Raster Data Stucture","text":"<pre><code>(dem_ter = rast(system.file(\"raster/srtm.tif\", package = \"spDataLarge\")))\nclass(dem_ter);plot(dem_ter)\n\n(dem_ras = raster(system.file(\"raster/srtm.tif\", package = \"spDataLarge\")))\nclass(dem_ras);plot(dem_ras)\n</code></pre>"},{"location":"spatial-r/#setup-the-coordinate-systems","title":"Setup the coordinate systems","text":"<pre><code>(geo = '+proj=longlat +datum=WGS84 +no_defs') # Unprojected world Geodetic System (degrees) CRS(\"+init=epsg:4326\")\n(utm36s = \"+proj=utm +zone=36 +south +datum=WGS84 +units=m +no_defs\") # Local UTM projection [36s] specific to KNP's longitude (meters)\n\nrsa_country.geo = rsa_country\nrsa_country.tm = spTransform(rsa_country.geo,CRS('+init=epsg:3395'))\nrsa_country.tm\n</code></pre>"},{"location":"spatial-r/#create-a-new-20km2-raster-based-on-the-extent-of-spdf","title":"Create a new 20km2 raster based on the extent of SPDF","text":"<pre><code>(grid20km = raster(extent(rsa_country.tm),res=c(20000,20000), crs=CRS('+init=epsg:3395')))\n(grid20km = raster(rsa_country.tm,res=c(20000,20000), crs=CRS('+init=epsg:3395')))\ngrid20km$site = 1:ncell(grid20km)\ngrid20km\n\n#### Plot the raster\n# Reset display settings\ndev.off()\n\n# Now plot\nplot(grid20km)\nplot(rsa_country.tm, add=T)\n\n# Remember to mask the background to NA\n# rsa_mask = rasterize(rsa_country.tm, grid20km)\nrsa_mask = rasterize(rsa_country.tm, grid20km[[1]], background=NA)\nplot(rsa_mask)\n# grid20km_mask = mask(grid20km,rsa_mask)\n# plot(grid20km_mask)\nplot(rsa_country.tm, add=T)\n\n#Plot this Single-Band Raster Data\n#--------------------------------------------------\ntm_shape(rsa_mask)+\n  tm_raster(style='pretty')+\n  tm_layout(legend.outside = TRUE)\n#--------------------------------------------------\n</code></pre>"},{"location":"spatial-r/#save-raster-to-local-drive","title":"Save raster to local drive","text":"<pre><code>writeRaster(rsa_mask, filename='grid20km_mask', format = 'GTiff')\n</code></pre>"},{"location":"spatial-r/#get-data-and-extract-to-area-of-interest","title":"Get data and extract to area of interest","text":"<p>WorldClim (https://www.worldclim.org/data/index.html) global climatic and weather data @ 30 arc-second (~1km) grid</p> <p>Bioclim variables Variable Description - BIO1  Annual Mean Temperature - BIO2  Mean Diurnal Range (Mean of monthly (max temp - min temp)) - BIO3  Isothermality (BIO2/BIO7) ( 100) - BIO4  Temperature Seasonality (standard deviation 100) - BIO5  Max Temperature of Warmest Month - BIO6  Min Temperature of Coldest Month - BIO7  Temperature Annual Range (BIO5-BIO6) - BIO8  Mean Temperature of Wettest Quarter - BIO9  Mean Temperature of Driest Quarter - BIO10     Mean Temperature of Warmest Quarter - BIO11     Mean Temperature of Coldest Quarter - BIO12     Annual Precipitation - BIO13     Precipitation of Wettest Month - BIO14     Precipitation of Driest Month - BIO15     Precipitation Seasonality (Coefficient of Variation) - BIO16     Precipitation of Wettest Quarter - BIO17     Precipitation of Driest Quarter - BIO18     Precipitation of Warmest Quarter - BIO19     Precipitation of Coldest Quarter <pre><code>bioclim = getData('worldclim', var='bio', res=10, path='Data') \nbioclim\n# gain(bioclim)=0.1 # Must be multipled by 0.1 to convert back to degrees Celsius. \n# # Also precipitation is in mm, so a gain of 0.1 would turn that into cm.\n\nplot(bioclim[[1:4]]) # just the first 3, since its slow\n</code></pre></p>"},{"location":"spatial-r/#subsetting-and-spatial-cropping","title":"Subsetting and spatial cropping","text":"<p>Crop using a Spatial polygon <pre><code># bio1.rsa = crop(bioclim[[1]], bbox(rsa_country))\nbio1.rsa = crop(bioclim[[1]], rsa_country)\nplot(bio1.rsa) #dimensions : 76, 98, 7448  (nrow, ncol, ncell) | resolution : 0.1666667, 0.1666667  (x, y)\n\n# Note: Masking is different to cropping i.e. you get NA values for outside polygon area\nbio1.rsa.mask = mask(bio1.rsa, rsa_country)\nplot(bio1.rsa.mask)\n</code></pre></p>"},{"location":"spatial-r/#spatial-aggregation","title":"Spatial aggregation","text":"<pre><code># Aggregate using a function\nbio1.rsax3 = aggregate(bio1.rsa, 3, fun=mean)\nplot(bio1.rsax3) #dimensions : 26, 33, 858  (nrow, ncol, ncell) | resolution : 0.5, 0.5  (x, y)\n\n# Raster calculations\ncellStats(bio1.rsa,range);cellStats(bio1.rsa,mean)\n</code></pre>"},{"location":"spatial-r/#extracting-raster-data","title":"Extracting Raster Data","text":"<pre><code>(bioclim.rsa = crop(bioclim, rsa_country))\nplot(bioclim.rsa[[1]])\nplot(bioclim.rsa[[1:4]])\n\n# define a new dataset of points to play with\npts = sampleRandom(bioclim.rsa,100,xy=T,sp=T)\n# plot(pts);axis(1);axis(2)\nplot(bioclim.rsa[[1]])\nplot(pts, add=T)\nhead(pts)\n\n# Extract data using a SpatialPoints object\nptsEmpty = pts[,1:2]\nhead(ptsEmpty)\npts.data = raster::extract(bioclim.rsa[[1:4]], ptsEmpty, df=T, sp=T)\nhead(pts.data)\n\n# Create histogram of extracted values\nsummary(pts.data)\n</code></pre>"},{"location":"spatial-r/#bin-data-using-custom-breaks","title":"Bin data using custom breaks","text":"<pre><code>pts.data@data = pts.data@data %&gt;% mutate(binBio1 = cut(bio1, breaks=c(0, 128, 150, 200, 241)))\n\n#perform binning with specific number of bins\npts.data@data = pts.data@data %&gt;% mutate(binBio1 = cut(bio1, breaks=3))\n\n# Plot histograms - examples\n# counts\nggplot(data.frame(pts.data@data), aes(x=binBio1)) +\n  geom_bar()\n\nggplot(data = pts.data@data, mapping = aes(x=binBio1,y=log10(bio1))) + \n  geom_jitter(aes(color='blue'),alpha=0.2) +\n  geom_boxplot(fill=\"bisque\",color=\"black\",alpha=0.3) + \n  labs(x='log bio1 value per bin') +\n  guides(color=FALSE) +\n  theme_minimal() \n</code></pre>"},{"location":"spatial-r/#qgis-workshop-in-progress","title":"QGIS Workshop (in progress)","text":"<p>A Free and Open Source Geographic Information System https://qgis.org/en/site/</p>"},{"location":"working/","title":"Working","text":""},{"location":"working/#list-of-contributors","title":"List of contributors","text":"<p>Sandra MacFadyen</p>"}]}